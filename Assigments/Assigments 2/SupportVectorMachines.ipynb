{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy import ndimage, fft\n",
    "from sklearn.preprocessing import normalize, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFluxProcessor:\n",
    "    \"\"\"Process light flux data with various signal processing techniques.\"\"\"\n",
    "\n",
    "    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n",
    "        \"\"\"Initialize processor with desired transformations.\n",
    "        \n",
    "        Args:\n",
    "            fourier: Apply Fourier transform if True\n",
    "            normalize: Apply normalization if True\n",
    "            gaussian: Apply Gaussian filtering if True\n",
    "            standardize: Apply standardization if True\n",
    "        \"\"\"\n",
    "        self.fourier = fourier\n",
    "        self.normalize = normalize\n",
    "        self.gaussian = gaussian\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def fourier_transform(self, data):\n",
    "        \"\"\"Apply Fast Fourier Transform to 1D time series data.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data\n",
    "            \n",
    "        Returns:\n",
    "            Magnitude of FFT result\n",
    "        \"\"\"\n",
    "        return np.abs(fft.fft(data, n=data.size))\n",
    "\n",
    "    def process(self, train_features, dev_features):\n",
    "        \"\"\"Process training and development datasets with selected transformations.\n",
    "        \n",
    "        Args:\n",
    "            train_features: Training features DataFrame\n",
    "            dev_features: Development features DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of processed (train_features, dev_features)\n",
    "        \"\"\"\n",
    "        # Apply Fourier transform\n",
    "        if self.fourier:\n",
    "            print(\"Applying Fourier...\")\n",
    "            train_shape = train_features.shape\n",
    "            dev_shape = dev_features.shape\n",
    "            \n",
    "            # Apply FFT to each row\n",
    "            train_features = train_features.apply(self.fourier_transform, axis=1)\n",
    "            dev_features = dev_features.apply(self.fourier_transform, axis=1)\n",
    "\n",
    "            # Convert Series of arrays back to DataFrame\n",
    "            train_processed = np.zeros(train_shape)\n",
    "            dev_processed = np.zeros(dev_shape)\n",
    "\n",
    "            for idx, row in enumerate(train_features):\n",
    "                train_processed[idx] = row\n",
    "\n",
    "            for idx, row in enumerate(dev_features):\n",
    "                dev_processed[idx] = row\n",
    "\n",
    "            train_features = pd.DataFrame(train_processed)\n",
    "            dev_features = pd.DataFrame(dev_processed)\n",
    "\n",
    "            # Use only first half of FFT output (symmetric data)\n",
    "            train_features = train_features.iloc[:, :(train_features.shape[1] // 2)].values\n",
    "            dev_features = dev_features.iloc[:, :(dev_features.shape[1] // 2)].values\n",
    "\n",
    "        # Normalize data\n",
    "        if self.normalize:\n",
    "            print(\"Normalizing...\")\n",
    "            train_features = pd.DataFrame(normalize(train_features))\n",
    "            dev_features = pd.DataFrame(normalize(dev_features))\n",
    "\n",
    "        # Apply Gaussian smoothing\n",
    "        if self.gaussian:\n",
    "            print(\"Applying Gaussian Filter...\")\n",
    "            train_features = ndimage.gaussian_filter(train_features, sigma=10)\n",
    "            dev_features = ndimage.gaussian_filter(dev_features, sigma=10)\n",
    "\n",
    "        # Standardize features\n",
    "        if self.standardize:\n",
    "            print(\"Standardizing...\")\n",
    "            scaler = StandardScaler()\n",
    "            train_features = scaler.fit_transform(train_features)\n",
    "            dev_features = scaler.transform(dev_features)\n",
    "\n",
    "        print(\"Finished Processing!\")\n",
    "        return train_features, dev_features\n",
    "\n",
    "def np_X_Y_from_df(dataframe):\n",
    "    \"\"\"Convert DataFrame to numpy arrays for features and binary labels.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: DataFrame containing features and LABEL column\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (features_array, labels_array) with labels converted to binary\n",
    "    \"\"\"\n",
    "    # Shuffle data for better training\n",
    "    dataframe = shuffle(dataframe)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    features = dataframe.drop([\"LABEL\"], axis=1)\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    # Convert labels to binary (True where LABEL==2)\n",
    "    raw_labels = np.array(dataframe[\"LABEL\"]).reshape((len(dataframe[\"LABEL\"]), 1))\n",
    "    binary_labels = raw_labels == 2\n",
    "    \n",
    "    return features_array, binary_labels\n",
    "\n",
    "def Load_and_Process(train_dataset_path, dev_dataset_path):\n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    df_train = pd.read_csv(train_dataset_path, encoding=\"ISO-8859-1\")\n",
    "    df_dev = pd.read_csv(dev_dataset_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "    # Split features and labels\n",
    "    train_features = df_train.drop(\"LABEL\", axis=1)\n",
    "    dev_features = df_dev.drop(\"LABEL\", axis=1)\n",
    "    train_labels = df_train[\"LABEL\"]\n",
    "    dev_labels = df_dev[\"LABEL\"]\n",
    "\n",
    "    # Process light flux data with multiple transformations\n",
    "    processor = LightFluxProcessor(fourier=True, normalize=True, \n",
    "                                gaussian=True, standardize=True)\n",
    "    processed_train_features, processed_dev_features = processor.process(train_features, dev_features)\n",
    "\n",
    "    # Rejoin processed features with labels\n",
    "    processed_train_df = pd.DataFrame(processed_train_features).join(pd.DataFrame(train_labels))\n",
    "    processed_dev_df = pd.DataFrame(processed_dev_features).join(pd.DataFrame(dev_labels))\n",
    "\n",
    "    # Convert to numpy arrays for model training\n",
    "    X_train, Y_train = np_X_Y_from_df(processed_train_df)\n",
    "    Y_train = Y_train.ravel()\n",
    "    X_dev, Y_dev = np_X_Y_from_df(processed_dev_df)\n",
    "    Y_dev = Y_dev.ravel()\n",
    "\n",
    "    # Get dataset dimensions\n",
    "    num_training_examples, feature_dimension = X_train.shape\n",
    "    output_dimension = Y_train.shape\n",
    "\n",
    "    # Display dataset information\n",
    "    print(f\"Training examples: {num_training_examples}\")\n",
    "    print(f\"Feature dimension: {feature_dimension}\")\n",
    "    print(f\"Output dimension: {output_dimension}\")\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev\n",
    "\n",
    "def Build_and_Train(X_train, Y_train, version = \"Linear\", degree=4, C = 1.0):\n",
    "    if version == \"Linear\":\n",
    "        model = LinearSVC(C=C)\n",
    "    elif version == \"Poly\":\n",
    "        model = SVC(kernel='poly', degree=degree, C=C)\n",
    "    elif version == \"RBF\":\n",
    "        model = SVC(kernel='rbf', C=C)\n",
    "    else:\n",
    "        print(\"Invalid version\")\n",
    "        \n",
    "    print(f\"Fitting {version} Model\")\n",
    "    start = time.time()\n",
    "    model.fit(X_train, Y_train)\n",
    "    finish = time.time()\n",
    "    print(f\"Training time: {finish - start:.2f} seconds\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def EvaluateModel(model, X_train, X_dev, Y_train, Y_dev):\n",
    "    # Predict and convert to binary classifications\n",
    "    train_outputs = model.predict(X_train)\n",
    "    dev_outputs = model.predict(X_dev)\n",
    "    train_outputs = np.rint(train_outputs)\n",
    "    dev_outputs = np.rint(dev_outputs)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy_train = accuracy_score(Y_train, train_outputs)\n",
    "    accuracy_dev = accuracy_score(Y_dev, dev_outputs)\n",
    "    precision_train = precision_score(Y_train, train_outputs)\n",
    "    precision_dev = precision_score(Y_dev, dev_outputs)\n",
    "    recall_train = recall_score(Y_train, train_outputs)\n",
    "    recall_dev = recall_score(Y_dev, dev_outputs)\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    try:\n",
    "        f1_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
    "        f1_dev = 2 * (precision_dev * recall_dev) / (precision_dev + recall_dev)\n",
    "    except ZeroDivisionError:\n",
    "        f1_train = 0\n",
    "        f1_dev = 0\n",
    "\n",
    "    # Confusion matrices\n",
    "    confusion_matrix_train = confusion_matrix(Y_train, train_outputs)\n",
    "    confusion_matrix_dev = confusion_matrix(Y_dev, dev_outputs)\n",
    "\n",
    "    # Print results summary\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
    "    print(f\"Development Accuracy: {accuracy_dev:.4f}\")\n",
    "    print(f\"Training Precision: {precision_train:.4f}\")\n",
    "    print(f\"Development Precision: {precision_dev:.4f}\")\n",
    "    print(f\"Training Recall: {recall_train:.4f}\")\n",
    "    print(f\"Development Recall: {recall_dev:.4f}\")\n",
    "    print(f\"Training F1 Score: {f1_train:.4f}\")\n",
    "    print(f\"Development F1 Score: {f1_dev:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Confusion Matrix (Training):\")\n",
    "    print(confusion_matrix_train)\n",
    "    print(\"\\nConfusion Matrix (Development):\")\n",
    "    print(confusion_matrix_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SVM with the \"Not Injected\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Applying Fourier...\n",
      "Normalizing...\n",
      "Applying Gaussian Filter...\n",
      "Standardizing...\n",
      "Finished Processing!\n",
      "Training examples: 5087\n",
      "Feature dimension: 1598\n",
      "Output dimension: (5087,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = \"./data/kepler/data_no_injection/exoTrain.csv\"\n",
    "dev_dataset_path = \"./data/kepler/data_no_injection/exoTest.csv\"\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev = Load_and_Process(train_dataset_path, dev_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Linear Model\n",
      "Training time: 3.70 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 1.0000\n",
      "Development Accuracy: 0.9877\n",
      "Training Precision: 1.0000\n",
      "Development Precision: 0.4167\n",
      "Training Recall: 1.0000\n",
      "Development Recall: 1.0000\n",
      "Training F1 Score: 1.0000\n",
      "Development F1 Score: 0.5882\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[5050    0]\n",
      " [   0   37]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[558   7]\n",
      " [  0   5]]\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"Linear\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Poly Model\n",
      "Training time: 0.07 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 1.0000\n",
      "Development Accuracy: 0.9807\n",
      "Training Precision: 1.0000\n",
      "Development Precision: 0.0000\n",
      "Training Recall: 1.0000\n",
      "Development Recall: 0.0000\n",
      "Training F1 Score: 0.0000\n",
      "Development F1 Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[5050    0]\n",
      " [   0   37]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[559   6]\n",
      " [  5   0]]\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"Poly\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RBF Model\n",
      "Training time: 0.20 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.9998\n",
      "Development Accuracy: 0.9912\n",
      "Training Precision: 1.0000\n",
      "Development Precision: 0.0000\n",
      "Training Recall: 0.9730\n",
      "Development Recall: 0.0000\n",
      "Training F1 Score: 0.0000\n",
      "Development F1 Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[5050    0]\n",
      " [   1   36]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[565   0]\n",
      " [  5   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacopocarotenuto/Documents/Università/Frati_Trappisti/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"RBF\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Network with the \"Injected\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Applying Fourier...\n",
      "Normalizing...\n",
      "Applying Gaussian Filter...\n",
      "Standardizing...\n",
      "Finished Processing!\n",
      "Training examples: 5087\n",
      "Feature dimension: 1598\n",
      "Output dimension: (5087,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = \"./data/kepler/data_injected/exoTrain.csv\"\n",
    "dev_dataset_path = \"./data/kepler/data_injected/exoTest.csv\"\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev = Load_and_Process(train_dataset_path, dev_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Linear Model\n",
      "Training time: 23.51 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.5813\n",
      "Development Accuracy: 0.5386\n",
      "Training Precision: 0.5889\n",
      "Development Precision: 0.5558\n",
      "Training Recall: 0.8462\n",
      "Development Recall: 0.8354\n",
      "Training F1 Score: 0.6945\n",
      "Development F1 Score: 0.6675\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[ 536 1690]\n",
      " [ 440 2421]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[ 43 211]\n",
      " [ 52 264]]\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"Linear\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Poly Model\n",
      "Training time: 16.15 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.5713\n",
      "Development Accuracy: 0.5404\n",
      "Training Precision: 0.5688\n",
      "Development Precision: 0.5597\n",
      "Training Recall: 0.9825\n",
      "Development Recall: 0.8006\n",
      "Training F1 Score: 0.7205\n",
      "Development F1 Score: 0.6589\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[  95 2131]\n",
      " [  50 2811]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[ 55 199]\n",
      " [ 63 253]]\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"Poly\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RBF Model\n",
      "Training time: 14.43 seconds\n",
      "Model Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.5669\n",
      "Development Accuracy: 0.5544\n",
      "Training Precision: 0.5653\n",
      "Development Precision: 0.5544\n",
      "Training Recall: 0.9951\n",
      "Development Recall: 1.0000\n",
      "Training F1 Score: 0.7210\n",
      "Development F1 Score: 0.7133\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Training):\n",
      "[[  37 2189]\n",
      " [  14 2847]]\n",
      "\n",
      "Confusion Matrix (Development):\n",
      "[[  0 254]\n",
      " [  0 316]]\n"
     ]
    }
   ],
   "source": [
    "model = Build_and_Train(X_train, Y_train, version=\"RBF\", C=1.0)\n",
    "EvaluateModel(model, X_train, X_dev, Y_train, Y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
